# AlexNet Paper Review
Reference : <a href='https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf'>ImageNet Classification with Deep Convolutional Neural Networks</a>
---
## 0.Abstract
우리는 1000개의 다른 클래스가 존재하는 ImageNet LSVRC-2010 경진대회에서 1.2백만개의 고화질 이미지를 분류하기 위해 크고,깊은 컨볼루션 네트워크를 학습하였다.
테스트 데이터에서 우리는 top-1 그리고 top-5 오류율 37.5%,17.0% 를 달성하였다. 이는 이전 state-of-art(SOTA) 보다 상당히 더 낫다.
그 신경망은 60 milion 개의 파라미터와 650,000개의 뉴런을 가지고 있고,5개의 컨볼루션 레이어로 구성되고, 이 레이어들 중 일부는 Max-Pooling layer가 붙어있다. 그리고 3개의 FC-layer를 사용하며 최종 출력계층에는 1000 way 소프트맥스를 가지고 있다.
학습을 더 빠르게 하기 위해, 우리는 포화하지 않는 뉴런을 사용하였고 매우 효율적인 컨볼루션 연산을 GPU에 시행하였다.
FC-layer에서 과적합(Overfitting)을 줄이기 위해 우리는 최근에 발전된 Regularizaion 방법인 Dropout을 사용했고 이는 매우 효과적인것을 증명하였다.
우리는 또한 ILSVRC-2012 경진대회 에서 이 모델을 변형하여 입력하였고 top-5 테스트 오류율 15.3%를 달성하여 우승하였다. 2번째로 우수한 모델은 top-5 테스트 오류율이 26.2% 였다. 

## 1.Introduction 
Object Recognition을 위한 최근 연구는 머신러닝 기법을 필수적으로 사용한다.
성능을 향상시키기 위해, 우리는 더 큰 데이터셋을 모으고,더 강력한 모델을 학습하고, 더 나은 과적합(Overfitting)을 막는 방법을 사용할 수 있었다.
최근까지 레이블링된 이미지 데이터셋은 상대적으로 작았다.
간단한 Recognition Task의 경우 이와같은 데이터 크기로 잘 해결될 수 있었다, 특히 그것들을 label-preserving transformation로 증강시킨다면
예를 들면 MNIST Digit Recognition Task의 현재 Best error rate(<0.3%)는 Human performance에 가깝다.
그러나 현실 세계에서의 Object들에 대해서는 상당히 가변적인것을 보여준다. 그래서 이것을 인식하는것을 배우기 위해서는 필수적으로 매우 큰 학습세트가 사용되어야 한다.
사실 작은 이미지 데이터셋의 단점들은 널리 알려져 있다 그러나 백만장의 이미지가 레이블된 데이터를 모으는 것은 최근이 되서야 가능해졌다.
그 새로운 큰 데이터셋은 LabelMe를 포함한다,이것은 완벽히 분리된 이미지들을 수십만개의 데이터로 구성되어있다, 그리고 ImageNet은 22,000개의 카테고리가 포함된 1500만개 이상의 많은 레이블된 고화질 이미지로 구성되어있다.

100만장의 이미지로부터 천개의 Object들을 학습하기 위해서는,우리는 더 큰 학습 Capacity를 가진 모델이 필요하다.
그러나 Object Recognition Task의 엄청난 복잡성은 의미한다 ImageNet만큼 큰 데이터셋을 사용하더라도 명확하게 인식 될 수 없다는 것을 
그것들의 Capacity는 조정될 수 있다 그것들의 깊이와 너비를 달리함으로써,그리고 그것들은 또한 강력하고 가장 정확한 추정을 만들어 낼 수 있다 the nature of images에 관하여
이와같이 비슷한 사이즈의 계층을 가진 표준 순방향 네트워크와 비교하였을 때,CNN들은 훨씬 더 적은 연결과 파라미터를 가지고 있고 더 쉽게 학습될 수 있다, 반면에 그들의 이론적으로 가장 best performance는 더 나빠질 것이다.
CNN의 매력적인 퀄리티와 그들의 local architecture의 상대적인 효율성에도 불구하고 그들은 아직까지 엄두도 내지 못할정도로 비용이 많이 든다 큰 규모 고화질 이미지에 적용하기에는 
운 좋게도 2D 컨볼루션의 고도의 최적화 실행이 짝지어진 현재 GPU들은 large CNN의 학습이 가능할 만큼 충분히 강력하다, 그리고 ImageNet과 같은 최근 데이터셋은 과적합(overfitting)없이 모델을 학습시키기 위한 충분히 레이블된 example들을 포함한다.

이 논문에 분배된 구체적인것들을 따르면 : 우리는 학습하였다 더 큰 컨볼루션 신경망중 하나를 최신 이미지넷의 subset으로 ILSVRC-2010 그리고 ILSVRC-2012 컴피티션에서 그리고 이 데이터셋으로 보고된것들 본적 없는 가장 최고의 결과를 달성하였다.
우리는 작성한 2D Convolution의 가장 최적화된 GPU 구현 그리고 컨볼루션 신경망 학습에서 다른 모든 작업들은 내재한다, 공식적으로 이용가능하다는 것을.
우리의 네트워크는 포함한다 많은 새롭고 흔치않은 특징들을 성능을 향상시키고 학습시간을 줄일 수 있는
우리의 네트워크의 크기는 명백한 과적합문제를 만들었다, 1.2백만개 레이블된 학습 example들도,그래서 우리는 사용하였다 몇몇의 효과적인 기법들을 과적합을 막을 수 있는
우리의 마지막 신경망은 포함한다 5개의 컨볼루션과 3개의 fc-layer를 그리고 이 깊이는 중요한것처럼 보여진다 : 우리는 찾았다 어느 컨볼루션 layer를 제거하더라고 결과는 성능이 안좋아진다라는 것을

끝에서는 그 네트워크의 크기는 제한된다 주로 현재 GPU들이 이용할 수 있는 메모리의 양이 얼마나 많은지 그리고 우리가 견딜수 있는 학습시간에 의해 
우리의 네트워크는 5일에서 6일 동안 두개의 GTX 580 3GB GPU에서 학습하였다.
모든 실험은 제한다 우리의 결과가 향샹될 수 있음을 기다림으로써 더 빠른 GPU와 더욱 더 커진 데이터셋이 이용가능하게 됨으로 써

## 6.Result
우리 네트워크는 top-1 과 top-5 테스트 오류율에서 각각 37.5% 와 17.0%를 달성했다.

우리는 또한 우리의 모델을 ILSVRC-2012 대회에 입력하였고 이 결과는 Table 2에 기록한 것이다.
ILSVRC-2012 테스트셋 레이블들은 공식적으로 사용이 가능하지 않기 때문에 우리는 우리가 시도한 모든 모델에 대한 테스트 오류율을 기록할 수 없었다.
이 도표의 남은 부분중에서, 우리는 Validation과 Test Set의 오류 비율을 상호교환할수 있게 사용한다 왜냐하면 우리의 경험에서 그것들은 0.1%보다 많게는 다르지 않았기 때문이다.
다섯개의 비슷한 CNN들의 예측들을 평균낸것은 16.4%의 오류율을 나타내었다.
ImageNet Fall 2011(15M images,22K categories) release된 전체를 분류하기 위해 마지막 pooling layer에 6번째 Convolutional layer 추가한 하나의 CNN을 학습하고 그리고 나서 그것을 ILSVRC-2012 에 "fine-tuning" 한것은 16.6%의 오류율을 나타내었다.
CNN 2개의 예측들을 평균낸 것은 Fall 2011에 release된 전체 데이터로 앞서 언급한 5개의 CNN들과 함께 pre-trained 되었고 그것들은 15.3%의 오류율을 나타내었다.
두번째로 우수한 대회 출품작은 26.2%의 오류율을 달성하였다.

![IMG_D3EB0D33955D-1](https://user-images.githubusercontent.com/76929568/215078042-fb1b8406-e158-416d-8a11-4b610847228f.jpeg)


마지막으로 우리는 또한 ImageNet의 Fall 2009 버전에서의 우리의 오류율을 기록하였다.
이 데이터셋에서 우리는 이미지들의 반은 훈련에 사용하고 반은 테스팅에 사용하는 문헌의 관례를 따랐다.
테스트셋으로 설립된것이 없었기 때문에 우리의 split은 이전 저자들이 사용한 split와는 필연적으로 다를것이다.
그러나 이것은 결과에 눈에 띄게 영향을 주진 않았다.
우리의 top-1 and top-5 오류율은 이 데이터셋에서 각각  67.4% 와 40.9% 이고 위에 묘사된 네트워크 그러나 마지막 Pooling layer에 여섯번째 Convolution layer가 추가된 것으로 이러한 오류율을 얻었다.
이 데이터셋에서 최고 성능은 각각 top-1 ,top-5 오류율이 78.1% 와 60.9% 였던 것이다.

